from typing import Dict, Any, List, Optional, Tuple
import time
import json
import os
import re

from ..BaseWorkflow import BaseWorkflow
from models.Base import BaseModel
from datasets.Dataset import Dataset
from datasets.APPSDataset import APPSDataset
from utils.results import Results
from utils.grammarcheck import GrammarChecker
from constants.verboseType import *


from agents.testing.EquivalenceClassAgent import EquivalenceClassAgent
from agents.testing.BoundaryValueAgent import BoundaryValueAgent
from agents.testing.DecisionTableAgent import DecisionTableAgent
from agents.testing.CauseEffectAgent import CauseEffectAgent
from agents.testing.OrthogonalTestAgent import OrthogonalTestAgent

# from agents.planning.WebSearchAgent import WebSearchAgent
# from agents.planning.SolutionSynthesisAgent import SolutionSynthesisAgent

# from agents.core.CodingAgent import CodingAgent
# from agents.core.CTOAgent import CTOAgent

# from agents.execution.DockerExecutor import DockerExecutor

class TeamCoderWorkflowWOattention(BaseWorkflow):
    """
    TeamCoderå·¥ä½œæµå®ç°ï¼ŒCTOç›‘ç£ä¸‹çš„å¤šæ™ºèƒ½ä½“åä½œä»£ç ç”Ÿæˆ
    """
    def __init__(
        self,
        model: BaseModel,
        dataset: Dataset,
        language: str,
        pass_at_k: int = 1,
        results: Optional[Results] = None,
        verbose: int = 1,
        web_search: bool = True,
        docker_execution: bool = True,
        max_test_time: int = 600,  # 10åˆ†é’Ÿ
        max_planning_time: int = 600,  # 10åˆ†é’Ÿ
        max_coding_time: int = 300,  # 5åˆ†é’Ÿ
        max_execution_time: int = 180,  # 3åˆ†é’Ÿ
        start_index: int = 0,  # æ·»åŠ start_indexå‚æ•°
    ):
        """
        åˆå§‹åŒ–TeamCoderå·¥ä½œæµ
        
        Args:
            model: æ¨¡å‹å®ä¾‹
            dataset: æ•°æ®é›†å®ä¾‹
            language: ç¼–ç¨‹è¯­è¨€
            pass_at_k: è¯„ä¼°æ—¶çš„pass@kå€¼
            results: ç»“æœè®°å½•å™¨å®ä¾‹
            verbose: è¾“å‡ºè¯¦ç»†ç¨‹åº¦
            web_search: æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢
            docker_execution: æ˜¯å¦ä½¿ç”¨Dockeræ‰§è¡ŒéªŒè¯
            max_test_time: æµ‹è¯•é˜¶æ®µæœ€å¤§æ—¶é—´(ç§’)
            max_planning_time: è§„åˆ’é˜¶æ®µæœ€å¤§æ—¶é—´(ç§’)
            max_coding_time: ç¼–ç é˜¶æ®µæœ€å¤§æ—¶é—´(ç§’)
            max_execution_time: æ‰§è¡Œé˜¶æ®µæœ€å¤§æ—¶é—´(ç§’)
            start_index: å¼€å§‹å¤„ç†çš„æ•°æ®é›†ç´¢å¼•ï¼Œé»˜è®¤ä¸º0
        """
        super().__init__(
            model=model,
            dataset=dataset,
            language=language,
            pass_at_k=pass_at_k,
            results=results,
            verbose=verbose,
            web_search=web_search,
            docker_execution=docker_execution,
            start_index=start_index,  # ä¼ é€’start_indexå‚æ•°
        )
        
        self.max_test_time = max_test_time
        self.max_planning_time = max_planning_time
        self.max_coding_time = max_coding_time
        self.max_execution_time = max_execution_time
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºç«èµ›å‹æ•°æ®é›†ï¼ˆAPPS ä½¿ç”¨ input/output æ ¼å¼ï¼Œä¸æ˜¯ assert è¯­å¥ï¼‰
        self.is_competitive = isinstance(self.dataset, APPSDataset)
        
        if self.verbose >= VERBOSE_MINIMAL and self.is_competitive:
            print(f"âœ“ æ£€æµ‹åˆ°ç«èµ›å‹æ•°æ®é›† (APPS)ï¼Œå°†ä½¿ç”¨ ExecEval è¿›è¡Œä»£ç è¯„ä¼°")
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self._init_agents()
        
    def _init_agents(self):
        """
        åˆå§‹åŒ–æ‰€æœ‰æ™ºèƒ½ä½“
        """
        from agents.core.CTOAgent import CTOAgent
        from agents.core.CodeAgent import CodeAgent
        from agents.core.DebugAgent import DebugAgent
        from agents.core.AttentionAgent import AttentionAgent
        from agents.core.ArbiterAgent import ArbiterAgent
        from agents.planning.SolutionPlanningAgent import SolutionPlanningAgent
        from agents.testing.TestAgent import TestAgent
        
        # æ³¨æ„åŠ›æ™ºèƒ½ä½“ - é˜¶æ®µ0ï¼šé‡ç‚¹åˆ†æ
        self.attention_agent = AttentionAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # CTOæ™ºèƒ½ä½“
        self.cto_agent = CTOAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # è§£å†³æ–¹æ¡ˆè§„åˆ’æ™ºèƒ½ä½“
        self.solution_planning_agent = SolutionPlanningAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # ä»£ç ç”Ÿæˆæ™ºèƒ½ä½“
        self.code_agent = CodeAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # è°ƒè¯•æ™ºèƒ½ä½“
        self.debug_agent = DebugAgent(
            verbose=self.verbose
        )
        
        # æµ‹è¯•æ™ºèƒ½ä½“ - ä½¿ç”¨å•ä¸€çš„ç»¼åˆæµ‹è¯•æ™ºèƒ½ä½“
        self.test_agent = TestAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # ä»²è£æ™ºèƒ½ä½“ - ç”Ÿæˆæœ€ç»ˆæ­£ç¡®çš„æµ‹è¯•å¥—ä»¶
        self.arbiter_agent = ArbiterAgent(
            model=self.model,
            verbose=self.verbose
        )
        
        # è®°å½•é˜¶æ®µ0çš„session_idï¼Œç”¨äºåç»­testcaseåˆ†æ
        self.stage0_attention_session_id = None

        # è¯­æ³•æ£€æŸ¥å™¨ï¼Œä½¿ç”¨ä»£ç æ™ºèƒ½ä½“ä½œä¸ºä¿®å¤ä»£ç†
        self.grammar_checker = GrammarChecker(
            fixer_agent=self.code_agent,
            verbose=self.verbose,
            max_fix_attempts=2,
        )
    
    def _extract_sample_io_from_test_cases(self, test_cases: list) -> list:
        """
        ä»test_casesä¸­æå–assertionå­—æ®µä½œä¸ºsample_io
        
        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«assertionå­—æ®µ
            
        Returns:
            sample_ioåˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨assertionçš„åŸå§‹å†…å®¹ï¼Œæœ€å¤šå–å‰3ä¸ª
        """
        sample_io = []
        
        if not test_cases:
            return sample_io
            
        for test_case in test_cases:
            assertion = test_case.get("assertion", "")
            if assertion:
                # ç›´æ¥ä½¿ç”¨assertionçš„åŸå§‹å†…å®¹ä½œä¸ºsample_io
                sample_io.append(assertion.strip())
                
        # å¦‚æœç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹é•¿åº¦å¤§äº3ï¼Œåªå–å‰3ä¸ª
        if len(sample_io) > 3:
            sample_io = sample_io[:3]
                
        return sample_io
    
    def _extract_assertions_from_test_cases(self, test_cases: list) -> list:
        """
        ä»test_casesä¸­æå–assertionå†…å®¹ï¼Œè¿”å›çº¯ç²¹çš„assertionåˆ—è¡¨
        
        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«assertionå­—æ®µ
            
        Returns:
            çº¯ç²¹çš„assertionåˆ—è¡¨ï¼Œå¦‚["assert func() == value", ...]
        """
        assertions = []
        
        if not test_cases:
            return assertions
            
        for test_case in test_cases:
            assertion = test_case.get("assertion", "")
            if assertion:
                # ç›´æ¥ä½¿ç”¨assertionçš„åŸå§‹å†…å®¹
                assertions.append(assertion.strip())
                
        return assertions
    
    def _correct_failed_testcases(self, problem_description: str, failed_testcases: list, all_testcases: list,attenton_analysis: str,sample_io: list,stage=5) -> list:
        """
        ä½¿ç”¨AttentionAgentï¼ˆç»§ç»­é˜¶æ®µ0çš„sessionï¼‰å¯¹å¤±è´¥çš„testcaseè¿›è¡Œæ”¹é”™
        
        Args:
            problem_description: é—®é¢˜æè¿°
            failed_testcases: å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹
            all_testcases: æ‰€æœ‰çš„æµ‹è¯•ç”¨ä¾‹
            
        Returns:
            æ”¹é”™åçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        """
       
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\nğŸ”§ AttentionAgentç»§ç»­é˜¶æ®µ0åˆ†æï¼Œæ”¹é”™{len(failed_testcases)}ä¸ªå¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹...")
        
        # æ„å»ºé”™è¯¯åˆ†æpromptï¼ˆä¸åŒ…å«ä»£ç ï¼‰
        failed_test_info = []
        if stage ==1:
            failed_test_info.append("# **there is no code,the Full Evidence Pool is most wrong,please fix them according to the <FATAL_POINT_ANALYSIS>**")
        else:
            for test in failed_testcases:
                failed_test_info.append(f"å¤±è´¥æµ‹è¯•: {test.get('test', '')} - é”™è¯¯: {test.get('error', '')}")
        
        correction_prompt = f"""
---
# Audit and Correct Test Cases Based on a Failure

## 1. Ground Truth (The Supreme Law - Immutable)
<PROBLEM_DESCRIPTION>
{problem_description}
</PROBLEM_DESCRIPTION>
<SAMPLE_IO>
{sample_io}
</SAMPLE_IO>

## 2. Primary Evidence: The Failure (Your Starting Point)
This is the most critical piece of evidence. Your investigation must start here.
<FAILED_TESTS>
{chr(10).join(failed_test_info)}
</FAILED_TESTS>

## 3. Secondary Clue: The Initial Analysis
This is a hypothesis from a previous agent. It may be helpful, but it can be wrong and must be validated against the failure.
<FATAL_POINT_ANALYSIS>
{attenton_analysis}
</FATAL_POINT_ANALYSIS>

## 4. Full Evidence Pool (To be Audited)
{chr(10).join(all_testcases)}

## Your Mission: From Failure, Deduce Truth, and Correct All Tests.

You must follow a rigorous, non-negotiable auditing protocol.

## Output (exactly TWO parts in order)

### Part 1: <thought> Block
Your auditing process MUST follow these explicit steps:
1.  **Analyze the Failure**: Look at the `FAILED_TESTS`. For one of the failures, identify the `input`, the `code's_actual_output`, and the `test's_expected_output`.
2.  **Establish the 'Rule of Truth' via Cross-Examination**: Now, you must determine who is correct: the code, or the test's expectation.
    a.  First, based **ONLY** on the **Supreme Law** (`PROBLEM_DESCRIPTION` and `SAMPLE_IO`), **manually calculate** what the **True Expected Output** for the failing input *should* be. **You must show your step-by-step reasoning based on the problem's definition.**
    b.  **Compare**: Is your calculated `True Expected Output` the same as the `code's_actual_output` or the `test's_expected_output`?
    c.  **Verdict**: Based on the comparison, state the single, correct 'Rule of Truth'. This rule must explain both the `Sample I/O` and why the test failed. *(e.g., "The Rule of Truth is that GPA checks must be `>`. The code's output of 'D' for input `1.0` was correct. The test's expectation of 'D+' was therefore FLAWED.")*
3.  **Audit ALL Test Cases Against the 'Rule of Truth'**: Now that you have the confirmed 'Rule of Truth', systematically apply it to **EVERY** test case in the `Full Evidence Pool`. For each one, state if it's CORRECT or if it's FLAWED and needs correction.
4.  **Final Conclusion**: Summarize which test cases are being corrected to align with the 'Rule of Truth'.

### Part 2: <corrected_tests> Block
List ALL test cases here. This includes all originally correct test cases from the pool plus the ones you have corrected based on your 'Rule of Truth'.
the format is
[
    "assert func(args) == expected_output",
    "assert func(args) == expected_output",
    ...
]
...
</corrected_tests>
"""
        
        try:
            # ä½¿ç”¨é˜¶æ®µ0çš„session_idç»§ç»­å¯¹è¯
            messages = [
                {"role": "user", "content": correction_prompt}
            ]
            
            response = self.attention_agent._call_model(messages, session_id=self.stage0_attention_session_id)

           
            # è§£æå“åº”ï¼Œæå–æ”¹æ­£åçš„æµ‹è¯•ç”¨ä¾‹
            import re
            corrected_testcases = []
            
            # å°è¯•ä»<corrected_tests>æ ‡ç­¾ä¸­æå–
            tests_match = re.search(r'<corrected_tests>(.*?)</corrected_tests>', response, re.DOTALL | re.IGNORECASE)
            if tests_match:
                tests_content = tests_match.group(1).strip()
                
                # å°è¯•è§£æJSONæ ¼å¼
                try:
                    import json
                    # æ¸…ç†JSONå†…å®¹ï¼Œç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                    json_content = tests_content
                    if json_content.startswith('```') and json_content.endswith('```'):
                        json_content = json_content[3:-3].strip()
                    if json_content.startswith('json'):
                        json_content = json_content[4:].strip()
                    
                    test_list = json.loads(json_content)
                    if isinstance(test_list, list):
                        corrected_testcases = test_list
                    else:
                        raise ValueError("JSONå†…å®¹ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
                        
                except (json.JSONDecodeError, ValueError) as e:
                    # JSONè§£æå¤±è´¥ï¼Œå°è¯•æŒ‰è¡Œè§£æ
                    if self.verbose >= VERBOSE_MINIMAL:
                        print(f"JSONè§£æå¤±è´¥: {e}ï¼Œå°è¯•æŒ‰è¡Œè§£æ")
                    lines = tests_content.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and line.startswith('assert'):
                            corrected_testcases.append(line)
            else:
                # å¤‡ç”¨è§£æï¼šç›´æ¥ä»æ•´ä¸ªå“åº”ä¸­æå–assertè¯­å¥
                lines = response.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    if line and line.startswith('assert'):
                        corrected_testcases.append(line)
            
            if not corrected_testcases:
                # å¦‚æœæ²¡æœ‰è§£æåˆ°æœ‰æ•ˆçš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¿”å›åŸå§‹æµ‹è¯•ç”¨ä¾‹
                if self.verbose >= VERBOSE_MINIMAL:
                    print("âš ï¸ æœªèƒ½è§£æåˆ°æœ‰æ•ˆçš„æ”¹æ­£ç»“æœï¼Œä½¿ç”¨åŸå§‹æµ‹è¯•ç”¨ä¾‹")
                return all_testcases
            
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"âœ… æˆåŠŸæ”¹é”™ï¼Œå¾—åˆ°{len(corrected_testcases)}ä¸ªæµ‹è¯•ç”¨ä¾‹")
                
            return corrected_testcases
            
        except Exception as e:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"âŒ æµ‹è¯•ç”¨ä¾‹æ”¹é”™å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æµ‹è¯•ç”¨ä¾‹")
            return all_testcases
    
    import json
    import re
    from typing import List, Dict, Any

    def _route_problem_complexity(
        self,
        problem_description: str,
        problem_sample_io: List[Dict[str, Any]]
    ) -> bool:
        """
        è·¯ç”±å‡½æ•°ï¼šåˆ¤æ–­é—®é¢˜æ˜¯å¦å¯ä»¥ç›´æ¥ç”Ÿæˆä»£ç 

        é€šè¿‡åˆ†æé—®é¢˜æè¿°å’Œæ ·ä¾‹IOï¼Œåˆ¤æ–­é—®é¢˜å¤æ‚åº¦ï¼š
        - True: ç®€å•é—®é¢˜ (Simple)ï¼Œå¯å°è¯•ç›´æ¥ç”Ÿæˆä»£ç 
        - False: å¤æ‚é—®é¢˜ (Complex)ï¼Œå¿…é¡»èµ°å®Œæ•´çš„è§„åˆ’-æµ‹è¯•-ç¼–ç æµç¨‹

        Args:
            problem_description: é—®é¢˜æè¿°
            problem_sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º

        Returns:
            bool: Trueè¡¨ç¤ºç®€å•é—®é¢˜ï¼ŒFalseè¡¨ç¤ºå¤æ‚é—®é¢˜
        """
        
        # æ³¨æ„ï¼šåœ¨f-stringä¸­ï¼ŒJSONçš„å·¦å³å¤§æ‹¬å·éœ€è¦è½¬ä¹‰ä¸º {{ å’Œ }}
        router_prompt = f"""
Role: Algorithm Complexity Classifier

Task:
Analyze the provided Python coding problem (description, function signature, and sample input/output) and classify it into one of two categories: "Simple" or "Complex".

Definitions:

1. [Simple]:
   - logic is linear and straightforward.
   - Can be solved with standard Python built-ins (e.g., list slicing, basic loops, string methods, set/dict lookups) without complex state management.
   - No complex mathematical derivations or specific algorithmic patterns (like DP, DFS/BFS) are needed.
   - Direct translation of the requirement into code.

2. [Complex] (The "Safe" Mode):
   - Requires ANY mathematical reasoning (geometry, number theory, polynomial evaluation, finding roots).
   - Requires specific algorithms (Binary Search, Two Pointers, Sliding Window, Recursion, Dynamic Programming, Graph/Tree traversal).
   - Requires handling tricky edge cases or specific conditional logic that deviates from standard behavior (e.g., "if X > Y, do a completely different logic Z").
   - Multi-step logical reasoning where step B depends on the complex result of step A.

Calibration Examples (Threshold for "Complex"):
- Example A: "Circular shift digits. IF shift > num_digits, return reversed digits." -> Classify as COMPLEX. (Reason: The specific conditional override makes it error-prone for simple direct generation).
- Example B: "Find zero of a polynomial." -> Classify as COMPLEX. (Reason: Requires mathematical implementation/numerical methods).
- Example C: "Return the sum of a list." -> Classify as SIMPLE.
- Example D: "Check if a string is a palindrome." -> Classify as SIMPLE.

Input Format:
This will provide the `problem_description` and `sample_io`.
---
Problem:
{problem_description}

Sample IO:
{problem_sample_io}
---

Output Format:
Return a single JSON object (no markdown, no extra text):
{{
    "category": "Simple" | "Complex",
    "reason": "Brief explanation < 20 words"
}}
"""

        messages = [
            {"role": "user", "content": router_prompt}
        ]

        try:
            # 1. è°ƒç”¨æ¨¡å‹
            router_session = self.cto_agent.start_new_session()
            response = self.cto_agent._call_model(messages, session_id=router_session)
            
            # 2. æ¸…æ´—å“åº”å†…å®¹ (å»é™¤å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—æ ‡è®°)
            content = response.strip()
            if "```" in content:
                # ä½¿ç”¨æ­£åˆ™æå– ```json ... ``` æˆ– ``` ... ``` ä¸­é—´çš„å†…å®¹
                match = re.search(r"```(?:json)?\s*(.*)\s*```", content, re.DOTALL)
                if match:
                    content = match.group(1)
            
            # 3. è§£æ JSON
            try:
                data = json.loads(content)
                category = data.get("category", "Complex") # é»˜è®¤ Complex
                reason = data.get("reason", "No reason provided")
            except json.JSONDecodeError:
                # å¦‚æœ JSON è§£æå½»åº•å¤±è´¥ï¼Œè®°å½•å¹¶å¯ç”¨å®‰å…¨æ¨¡å¼
                if self.verbose >= VERBOSE_MINIMAL:
                    print(f"\nâš ï¸ Router JSON Decode Error. Raw response: {content[:50]}...")
                return False  # Default to Complex

            # 4. åšå‡ºå†³ç­–
            # åªæœ‰æ˜ç¡®æ ‡è®°ä¸º "Simple" æ—¶æ‰è¿”å› True
            if category.lower() == "simple":
                decision = True
                log_tag = "SIMPLE (Direct Gen)"
            else:
                decision = False
                log_tag = "COMPLEX (Full Workflow)"

            # 5. æ—¥å¿—è¾“å‡º
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\nğŸ§­ Router Decision: {log_tag}")
                if self.verbose >= VERBOSE_FULL:
                    print(f"   Reason: {reason}")

            return decision

        except Exception as e:
            # 6. å¼‚å¸¸å¤„ç†ï¼šä»»ä½•ç¯èŠ‚å‡ºé”™ï¼Œéƒ½é»˜è®¤èµ°å¤æ‚æµç¨‹ï¼ˆå®‰å…¨å…œåº•ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\nâš ï¸ Router System Error: {e}, defaulting to COMPLEX workflow")
            return False
        
    def process_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªé—®é¢˜é¡¹
        
        Args:
            item: é—®é¢˜é¡¹
            
        Returns:
            å¤„ç†ç»“æœ
        """
        import time
        start_time = time.time()
        self.model.start_token_count()
        problem_id = item[self.dataset.id_key]
        problem_description = self.dataset.get_prompt(item)
        problem_sample_io = item["sample_io"]
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'='*50}\nå¤„ç†é—®é¢˜ {problem_id}\n{'='*50}")
            print(f"é—®é¢˜æè¿°:\n{problem_description}\n")
        
        # use_direct = self._route_problem_complexity(
        #     problem_description=problem_description,
        #     problem_sample_io=problem_sample_io
        # )
        code_result = {}
        #if use_direct: 
        code_result = self._generate_init_code(problem_description, problem_sample_io=problem_sample_io, item=item)
        generated_code = "" # code_result.get("success", False) is False
        if code_result.get("success", False) is False:
            print(f"âŒ åˆå§‹åŒ–ä»£ç ç”Ÿæˆå¤±è´¥: {code_result.get('error', '')}")
            error_code = code_result.get("code", "")

            error_info = code_result.get("error","")

            # é˜¶æ®µé›¶: é‡ç‚¹åˆ†æ - æ‰¾å‡ºæœ€å®¹æ˜“è¢«å¿½è§†çš„è‡´å‘½å…³é”®ç‚¹
            #attention_analysis = self._analyze_critical_points(problem_description, problem_sample_io,error_code,error_info)
            attention_analysis={
            "fatal_points": "none",
            "recheck": "none",
            "raw_response": "none",
            "analysis_time": "none"
            }

            # test_cases=test_scenarios_list
            test_cases = ["consider the sample io"]
            thought_content=""

            technical_plan=""
            # é˜¶æ®µä¸‰: æ™ºèƒ½ç¼–ç ç”Ÿæˆ
            code_result = self._generate_code(problem_description, test_cases=test_cases, parsed_assertions=test_cases, thought_content=thought_content, problem_sample_io=problem_sample_io, technical_plan=technical_plan, attention_analysis=attention_analysis,error_code=error_code,error_info=error_info, item=item)

            # è·å–ç”Ÿæˆçš„ä»£ç 
            generated_code = code_result.get("code", "")

            # ç«‹å³è¯„ä¼°ç”Ÿæˆçš„ä»£ç ï¼ˆä½¿ç”¨pass@kæ–¹å¼ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nç«‹å³è¯„ä¼°ç”Ÿæˆçš„ä»£ç  (pass@1):")
        else:
            generated_code = code_result.get("code", "")

        try:
            # è·å–æ•°æ®é›†ç±»å‹
            dataset_type = self.dataset.__class__.__name__.lower()
            
            # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©è¯„ä¼°æ–¹å¼
            if "apps" in dataset_type:
                # APPS æ•°æ®é›†ï¼šä½¿ç”¨ ExecEval è¯„ä¼°å®Œæ•´çš„éšè—æµ‹è¯•ç”¨ä¾‹
                if self.verbose >= VERBOSE_MINIMAL:
                    print("\n=== æœ€ç»ˆè¯„ä¼°ï¼šä½¿ç”¨ ExecEval æµ‹è¯•å®Œæ•´éšè—æµ‹è¯•é›† ===")
                
                passed = self.dataset.evaluate(
                    item=item,
                    code=generated_code,
                    language=self.language
                )
                
                # APPS æ•°æ®é›†çš„ evaluate æ–¹æ³•è¿”å›å¸ƒå°”å€¼
                pass_rate = 1.0 if passed else 0.0
                
                if self.verbose >= VERBOSE_MINIMAL:
                    test_count = len(item.get("test_list", []))
                    print(f"è¯„ä¼°ç»“æœ: {'âœ… é€šè¿‡' if passed else 'âŒ å¤±è´¥'}")
                    print(f"æµ‹è¯•ç”¨ä¾‹æ•°é‡: {test_count}")
                    print(f"é€šè¿‡ç‡: {pass_rate:.2%}")
            
            elif "humaneval" in dataset_type or "mbpp" in dataset_type:
                # HumanEval/MBPP æ•°æ®é›†ï¼šä½¿ç”¨ pass@k è¯„ä¼°å‡½æ•°
                from evaluations.pass_at_k import evaluate_humaneval_problem, evaluate_mbpp_problem
                
                if "humaneval" in dataset_type:
                    evaluate_fn = evaluate_humaneval_problem
                elif "mbpp" in dataset_type:
                    evaluate_fn = evaluate_mbpp_problem
                else:
                    evaluate_fn = evaluate_humaneval_problem
                
                # ä½¿ç”¨pass@kè¯„ä¼°ï¼ˆk=1ï¼‰
                eval_result = evaluate_fn(
                    problem=item,
                    solutions=[generated_code],
                    timeout=30
                )
                
                # è§£æç»“æœ
                passed = len(eval_result.get("correct", [])) > 0
                pass_rate = eval_result.get("pass_rate", 0.0)
                
                if self.verbose >= VERBOSE_MINIMAL:
                    print(f"è¯„ä¼°ç»“æœ: {'é€šè¿‡' if passed else 'å¤±è´¥'}")
                    print(f"é€šè¿‡ç‡: {pass_rate:.2%}")
                    
                    # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ªé”™è¯¯
                    errors = eval_result.get("errors", [])
                    if errors and self.verbose >= VERBOSE_FULL:
                        print(f"é”™è¯¯ä¿¡æ¯: {errors[0][1]}")
            
            else:
                # æœªçŸ¥æ•°æ®é›†ç±»å‹ï¼Œå°è¯•ä½¿ç”¨é€šç”¨è¯„ä¼°
                if self.verbose >= VERBOSE_MINIMAL:
                    print(f"âš ï¸ æœªçŸ¥æ•°æ®é›†ç±»å‹: {dataset_type}ï¼Œä½¿ç”¨é»˜è®¤ HumanEval è¯„ä¼°")
                
                from evaluations.pass_at_k import evaluate_humaneval_problem
                eval_result = evaluate_humaneval_problem(
                    problem=item,
                    solutions=[generated_code],
                    timeout=5
                )
                
                passed = len(eval_result.get("correct", [])) > 0
                pass_rate = eval_result.get("pass_rate", 0.0)
                
        except Exception as e:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"âŒ è¯„ä¼°æ—¶å‡ºé”™: {str(e)}")
                import traceback
                if self.verbose >= VERBOSE_FULL:
                    traceback.print_exc()
            passed = False
            pass_rate = 0.0
        
        # æ„å»ºç»“æœ
        end_time = time.time()
        total_time = end_time - start_time
        tokens_used = self.model.end_token_count()
        result_dict = {
            "problem_id": problem_id,
            "passed": passed,
            "pass_rate": pass_rate,
            "code": generated_code,
            "total_time": total_time,
            "tokens_used": tokens_used
        }
        
        return result_dict

    def _analyze_critical_points_1(self, problem_description: str, sample_io: List[str] = None, error_code: str = "", error_info: List[str] = None) -> Dict[str, Any]:
        """
        é˜¶æ®µé›¶ï¼šåˆ†æé—®é¢˜ä¸­æœ€å®¹æ˜“è¢«å¿½è§†çš„è‡´å‘½å…³é”®ç‚¹
        
        Args:
            problem_description: é—®é¢˜æè¿°
            sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            
        Returns:
            å…³é”®ç‚¹åˆ†æç»“æœ
        """
        import time
        start_time = time.time()
        none_sample_io = False
        if len(sample_io) == 0 :
            sample_io = ["attention this problem has no sample io,so you must read the problem description carefully"]
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'='*50}")
            print("é˜¶æ®µé›¶: é‡ç‚¹åˆ†æ - å¯»æ‰¾æœ€å®¹æ˜“è¢«å¿½è§†çš„è‡´å‘½å…³é”®ç‚¹")
            print(f"{'='*50}")
        attention_session_id = self.attention_agent.start_new_session()
        self.stage0_attention_session_id = attention_session_id  # ä¿å­˜session_idä¾›åç»­testcaseåˆ†æä½¿ç”¨
        
        # Stage 0.1: Analyze the blueprint to find fatal traps.
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nStage 0.1: Analyzing blueprint for fatal traps...")

        blueprint_result_str=""
        attention_result = self.attention_agent.analyze_traps(
            problem_blueprint_json=blueprint_result_str or "",
            problem_description=problem_description,
            sample_io=sample_io or [],
            error_code=error_code,
            error_info=error_info or [],
            session_id=attention_session_id
        )
        print(f"\nğŸ” AttentionAgentåˆ†æç»“æœ (raw):\n{attention_result}\n")
        
        # å¤„ç†åˆ†æç»“æœ
        fatal_points = attention_result.get("fatal_points", "")
        recheck = attention_result.get("recheck", "")
        trap = attention_result.get("raw_response", "")

        # Stage 0.2: Generate a structured blueprint of the problem.
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nStage 0.2: Generating problem blueprint...")
        blueprint_result = self.attention_agent.generate_blueprint(
            problem_description=problem_description,
            sample_io=sample_io or [],
            error_code=error_code,
            error_info=error_info or [],
            trap=trap,
            session_id=attention_session_id
        )
        
        import json
        print(f"\nğŸ”§ Blueprint generation result (raw):\n{blueprint_result}\n")
        def extract_summary_rule(blueprint_result):
            # å°è¯•ä»blueprint_jsonæå–ï¼ˆå³ä½¿ä¸ºç©ºä¹Ÿä¸ä¼šæŠ¥é”™ï¼‰
            if 'blueprint_json' in blueprint_result and blueprint_result['blueprint_json']:
                try:
                    return blueprint_result['blueprint_json']['summary-rule']
                except KeyError:
                    pass  # ç»§ç»­å°è¯•å…¶ä»–è·¯å¾„
                
            # ä»raw_responseæå–ï¼ˆå¤„ç†ä¸ºç©ºæˆ–è§£æå¤±è´¥çš„æƒ…å†µï¼‰
            if 'raw_response' in blueprint_result:
                print("å°è¯•ä»raw_responseä¸­æå–summary-rule...")
                try:
                    
                    raw_dict =json.loads(blueprint_result['raw_response'])
                    print(f"è§£æåçš„raw_responseå†…å®¹: {raw_dict}")
                    return raw_dict['summary-rule']
                except (json.JSONDecodeError, KeyError):
                    return blueprint_result['raw_response']
                
            # æ‰€æœ‰è·¯å¾„å¤±è´¥æ—¶è¿”å›None
            return None

        blueprint_result_str = json.dumps(blueprint_result.get("raw_response", {}))
        # æå–å¹¶æ‰“å°ç»“æœ
        summary_rule = extract_summary_rule(blueprint_result)

        print(f"summary_rule: {summary_rule}")

  
        attention_result["raw_response"] = {"Rules": summary_rule, "Traps": attention_result.get("raw_response", "")}

        
        if none_sample_io:
            sample_io = []

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        elapsed_time = time.time() - start_time
        
        # è¿”å›AttentionAgentçš„åˆ†æç»“æœ
        return {
            "fatal_points": fatal_points,
            "recheck": recheck,
            "raw_response": attention_result.get("raw_response", ""),
            "analysis_time": elapsed_time
        }
        
        
  

    def _analyze_critical_points(self, problem_description: str, sample_io: List[str] = None, error_code: str = "", error_info: List[str] = None) -> Dict[str, Any]:
        """
        é˜¶æ®µé›¶ï¼šåˆ†æé—®é¢˜ä¸­æœ€å®¹æ˜“è¢«å¿½è§†çš„è‡´å‘½å…³é”®ç‚¹
        
        Args:
            problem_description: é—®é¢˜æè¿°
            sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            
        Returns:
            å…³é”®ç‚¹åˆ†æç»“æœ
        """
        import time
        start_time = time.time()
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'='*50}")
            print("é˜¶æ®µé›¶: é‡ç‚¹åˆ†æ - å¯»æ‰¾æœ€å®¹æ˜“è¢«å¿½è§†çš„è‡´å‘½å…³é”®ç‚¹")
            print(f"{'='*50}")
        attention_session_id = self.attention_agent.start_new_session()
        self.stage0_attention_session_id = attention_session_id  # ä¿å­˜session_idä¾›åç»­testcaseåˆ†æä½¿ç”¨
        
        # ä½¿ç”¨AttentionAgentè¿›è¡Œé‡ç‚¹åˆ†æ
        attention_result = self.attention_agent.find_fatal_points(
            problem_description=problem_description,
            sample_io=sample_io or [],
            error_info=error_info or [],
            error_code=error_code,
            session_id=attention_session_id
        )
        
        # å¤„ç†åˆ†æç»“æœ
        fatal_points = attention_result.get("fatal_points", "")
        recheck = attention_result.get("recheck", "")
        
        # # AttentionAgentè‡ªæˆ‘çº é”™é˜¶æ®µ
        # if self.verbose >= VERBOSE_MINIMAL:
        #     print(f"\nğŸ”§ AttentionAgentè¿›è¡Œè‡ªæˆ‘çº é”™...")


        # attention_session_id = self.attention_agent.start_new_session()
        #  # ä¿å­˜session_idä¾›åç»­testcaseåˆ†æä½¿ç”¨
        # self.stage0_attention_session_id = attention_session_id
        # self_correction_result = self.attention_agent.self_correction(
        #     problem_description=problem_description,
        #     sample_io=sample_io or [],
        #     fatal_points=fatal_points,
        #     recheck=recheck,
        #     session_id=attention_session_id
        # )
        
        # # ä½¿ç”¨çº é”™åçš„ç»“æœ
        # final_fatal_points = self_correction_result.get("fatal_points", fatal_points)
        # final_recheck = self_correction_result.get("recheck", recheck)
        
        # if self.verbose >= VERBOSE_MINIMAL:
        #     print(f"\nğŸ” AttentionAgentè‡ªæˆ‘çº é”™åçš„ç»“æœ:")
        #     print(f"   å…³é”®ç‚¹: {final_fatal_points}")
        #     if final_recheck:
        #         print(f"   å¤æŸ¥å†…å®¹: {final_recheck}")
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        elapsed_time = time.time() - start_time
        
        # è¿”å›AttentionAgentçš„åˆ†æç»“æœ
        return {
            "fatal_points": fatal_points,
            "recheck": recheck,
            "raw_response": attention_result.get("raw_response", ""),
            "analysis_time": elapsed_time
        }
        
        # CTOå®¡æŸ¥é˜¶æ®µï¼šé€ä¸ªæ£€æŸ¥sample IOï¼ŒéªŒè¯åˆ†ææ˜¯å¦æ­£ç¡®
        if sample_io:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\nğŸ” CTOå®¡æŸ¥é˜¶æ®µï¼šéªŒè¯åˆ†ææ˜¯å¦ç¬¦åˆSample IO...")
            
            reviewed_points = self._cto_review_attention_analysis(
                problem_description=problem_description,
                attention_analysis=fatal_points,
                sample_io=sample_io
            )
            
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\nğŸ” CTOå®¡æŸ¥åçš„å…³é”®ç‚¹:")
                print(f"   {reviewed_points}")
            
            fatal_points = reviewed_points
        
        elapsed_time = time.time() - start_time
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\né‡ç‚¹åˆ†æå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"{'='*50}\n")
        
        return {
            "fatal_points": fatal_points,
        }
    
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\né‡ç‚¹åˆ†æå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            print(f"{'='*50}\n")
        
        return {
            "fatal_points": fatal_points,
        }
    
    def _cto_review_attention_analysis(self, problem_description: str, attention_analysis: str, sample_io: List[str]) -> str:
        """
        CTOå®¡æŸ¥AttentionAgentçš„åˆ†æï¼Œé€ä¸ªæ£€æŸ¥sample IOéªŒè¯åˆ†ææ˜¯å¦æ­£ç¡®
        
        Args:
            problem_description: é—®é¢˜æè¿°
            attention_analysis: AttentionAgentçš„åˆ†æç»“æœ
            sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            
        Returns:
            CTOå®¡æŸ¥åçš„ä¿®æ­£åˆ†æ
        """
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'-'*50}\nCTOå®¡æŸ¥AttentionAgentåˆ†æ\n{'-'*50}")
        
        # æ„å»ºCTOå®¡æŸ¥çš„æç¤º
        review_prompt = f"""
As a CTO, please carefully review the attention analysis provided by the AttentionAgent against each sample I/O case.

## Problem Description
{problem_description}

## AttentionAgent's Analysis
{attention_analysis}

## Sample I/O Cases to Verify Against
{chr(10).join([f"Sample {i+1}: {io}" for i, io in enumerate(sample_io)])}

## Your Task
Please verify the AttentionAgent's analysis word by word against each sample I/O case:

1. **Examine each statement** in the analysis to ensure it accurately reflects what the sample I/O demonstrates
2. **Check each sample I/O** individually to verify if the analysis correctly identifies the critical points
3. **Identify any misunderstandings** where the analysis doesn't match what the sample I/O actually shows
4. **Correct any errors** by providing the accurate interpretation based on the sample I/O

## Requirements
- Be extremely precise and literal in your verification
- If any part of the analysis contradicts or misinterprets the sample I/O, correct it
- Focus on factual accuracy rather than general insights
- Ensure every word in your corrected analysis can be directly verified by the sample I/O


<MOCK>!!!The sample io is always correct,so you couldn't doubt the sample io!!!Simulate whether each sample input/output (sampleio) conforms to your new analysis. Particularly focus on simulating some special sampleio cases. If a sampleio passes the simulation, include it in your new analysis; if it fails, document the reasons for the failure.
</MOCK>
Please return only in this **format** use <CORRECTED_ANALYSIS> and </CORRECTED_ANALYSIS>:
<CORRECTED_ANALYSIS>
Write down the correct critical flaws here, preferably with complex examples for explanationâ€”avoid making them overly simplistic.
</CORRECTED_ANALYSIS>
"""
        
        # ä½¿ç”¨CTO Agentè¿›è¡Œå®¡æŸ¥
        try:
            messages = [
                {"role": "system", "content": "You are a CTO responsible for ensuring technical accuracy. Your task is to verify and correct analysis against concrete sample data."},
                {"role": "user", "content": review_prompt}
            ]
            
            # åˆ›å»ºæ–°çš„sessionç”¨äºé˜¶æ®µ0çš„CTOæ£€æŸ¥
            stage0_cto_session = self.cto_agent.start_new_session()
            cto_response = self.cto_agent._call_model(messages, session_id=stage0_cto_session)
            
            # ä¿å­˜session IDä¾›åç»­ä½¿ç”¨
            self.stage0_cto_session_id = stage0_cto_session
            
            # æå–ä¿®æ­£åçš„åˆ†æ
            import re
            corrected_match = re.search(r'<CORRECTED_ANALYSIS>\s*(.*?)\s*</CORRECTED_ANALYSIS>', cto_response, re.DOTALL | re.IGNORECASE)
            
            if corrected_match:
                corrected_analysis = corrected_match.group(1).strip()
                if self.verbose >= VERBOSE_FULL:
                    print(f"CTOå®¡æŸ¥å®Œæˆï¼ŒåŸåˆ†æé•¿åº¦: {len(attention_analysis)}, ä¿®æ­£åé•¿åº¦: {len(corrected_analysis)}")
                return corrected_analysis
            else:
                if self.verbose >= VERBOSE_MINIMAL:
                    print("CTOå®¡æŸ¥æœªè¿”å›æ ¼å¼åŒ–ç»“æœï¼Œä½¿ç”¨åŸåˆ†æ")
                return attention_analysis
                
        except Exception as e:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"CTOå®¡æŸ¥è¿‡ç¨‹å‡ºé”™: {e}ï¼Œä½¿ç”¨åŸåˆ†æ")
            return attention_analysis
    
    def _final_fatal_check(self, code: str, problem_description: str, session_id: str) -> str:
        """
        æœ€ç»ˆè‡´å‘½æ£€æŸ¥ï¼šç»“åˆé˜¶æ®µ0çš„åˆ†ææ£€æŸ¥ä»£ç ä¸­çš„è‡´å‘½é—®é¢˜
        
        Args:
            code: è¦æ£€æŸ¥çš„ä»£ç 
            problem_description: é—®é¢˜æè¿°
            session_id: é˜¶æ®µ0çš„CTO session ID
            
        Returns:
            æ£€æŸ¥å¹¶å¯èƒ½ä¿®æ­£åçš„ä»£ç 
        """
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'-'*50}\næœ€ç»ˆè‡´å‘½æ£€æŸ¥ï¼šç»“åˆé˜¶æ®µ0åˆ†ææ£€æŸ¥ä»£ç \n{'-'*50}")
        
        # æ„å»ºç®€æ´çš„æ£€æŸ¥æç¤º
        check_prompt = f"""
ç»“åˆä½ ä¹‹å‰çš„åˆ†æï¼Œä»”ç»†æŸ¥çœ‹ä»¥ä¸‹ä»£ç æœ‰ä»€ä¹ˆè‡´å‘½çš„ã€å®¹æ˜“å¿½è§†çš„é—®é¢˜ï¼Œå¦‚æœæœ‰è¯·ä¿®æ”¹ã€‚

## Problem Description
{problem_description}

## Current Code
```python
{code}
```

è¯·ä»”ç»†æ£€æŸ¥ä»£ç ä¸­æ˜¯å¦å­˜åœ¨ä¸ä½ ä¹‹å‰åˆ†æçš„è‡´å‘½å…³é”®ç‚¹ç›¸å…³çš„é—®é¢˜ã€‚ç‰¹åˆ«æ˜¯èƒ½å¦é€šè¿‡ sampleã€‚å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·ä¿®æ”¹ä»£ç ã€‚

è¿”å›æ ¼å¼ï¼š
<FINAL_CODE>
ä¿®æ­£åçš„å®Œæ•´ä»£ç ï¼ˆå¦‚æœæ— éœ€ä¿®æ”¹åˆ™è¿”å›åŸä»£ç ï¼‰
</FINAL_CODE>
"""
        
        try:
            # ä½¿ç”¨é˜¶æ®µ0çš„sessionç»§ç»­å¯¹è¯
            self.cto_agent.set_active_session(session_id)
            messages = [
                {"role": "user", "content": check_prompt}
            ]
            
            cto_response = self.cto_agent._call_model(messages, session_id=session_id, include_history=True)
            
            # æå–æœ€ç»ˆä»£ç 
            import re
            code_match = re.search(r'<FINAL_CODE>\s*(.*?)\s*</FINAL_CODE>', cto_response, re.DOTALL | re.IGNORECASE)
            
            if code_match:
                final_code = code_match.group(1).strip()
                if self.verbose >= VERBOSE_FULL:
                    print(f"æœ€ç»ˆæ£€æŸ¥å®Œæˆï¼ŒåŸä»£ç é•¿åº¦: {len(code)}, æ£€æŸ¥åé•¿åº¦: {len(final_code)}")
                return final_code
            else:
                if self.verbose >= VERBOSE_MINIMAL:
                    print("æœ€ç»ˆæ£€æŸ¥æœªè¿”å›æ ¼å¼åŒ–ä»£ç ï¼Œä½¿ç”¨åŸä»£ç ")
                return code
                
        except Exception as e:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"æœ€ç»ˆæ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {e}ï¼Œä½¿ç”¨åŸä»£ç ")
            return code
     
   
    
    def _generate_test_cases(self, problem_description: str, sample_io: List[str] = None, attention_analysis: Dict[str, Any] = None, stage_error_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        é˜¶æ®µä¸€: CTOç›‘ç£çš„æµ‹è¯•ç”¨ä¾‹åä½œç”Ÿæˆ
        
        Args:
            problem_description: é—®é¢˜æè¿°
            sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            attention_analysis: é˜¶æ®µé›¶çš„é‡ç‚¹åˆ†æç»“æœ
            
        Returns:
            ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
        """
        start_time = time.time()
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'-'*50}\né˜¶æ®µä¸€: CTOç›‘ç£çš„æµ‹è¯•ç”¨ä¾‹åä½œç”Ÿæˆ\n{'-'*50}")
        

        # ä½¿ç”¨ç»¼åˆæµ‹è¯•æ™ºèƒ½ä½“ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nä½¿ç”¨ç»¼åˆæµ‹è¯•æ™ºèƒ½ä½“ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
        test_session_id = self.test_agent.start_new_session()
       
        
        test_cases = self.test_agent.generate_test_cases(problem_description, sample_io=sample_io or [])
        
        # è§£æTestAgentè¿”å›ï¼šthoughtä¸ç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹
        test_propose = ""

        if isinstance(test_cases, dict):
            test_propose = test_cases.get("input", "")
            
        
        print(f"\n\nç»¼åˆæµ‹è¯•ç”¨ä¾‹\n\n: {test_cases}")

        attention_dict_str = attention_analysis.get("raw_response", "") if attention_analysis else ""
        attention_analysis = {"attention_analysis": attention_dict_str} if attention_dict_str else None
        test_cases = self.test_agent.evaluate_single_test(problem_description,assertion=test_propose,sample_io=sample_io,attention_analysis=attention_analysis)

                # è§£æTestAgentè¿”å›ï¼šthoughtä¸ç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹
        test_resolve = ""

        if isinstance(test_cases, dict):
            test_resolve = test_cases.get("assertion", "")
        print(f"\n\nç»¼åˆæµ‹è¯•ç”¨ä¾‹ç»“æœ\n\n: {test_resolve}")



        return test_resolve
        # å°†thoughtåŒ…è£…æˆå­—å…¸ä»¥ä¾›ä¸‹æ¸¸ä½¿ç”¨
        test_agent_attention = {"fatal_points": test_propose} if test_propose else None

        if self.verbose >= VERBOSE_FULL:
            print("ç»¼åˆæµ‹è¯•ç”¨ä¾‹(thought):", (test_agent_thought[:200] + '...') if len(test_agent_thought) > 200 else test_agent_thought)
            print("ç»¼åˆæµ‹è¯•ç”¨ä¾‹(structured):", test_agent_structured)
        
        # æ”¶é›†æµ‹è¯•ç»“æœ
        all_test_results = [test_agent_structured]
        
        
        # # CTOæ€»ç»“æµ‹è¯•ç”¨ä¾‹ï¼ˆé˜¶æ®µä¸€æš‚æ—¶å–æ¶ˆï¼Œæ”¹ä¸ºAttentionAgentæ”¹é”™æ–¹æ¡ˆï¼‰
        # if self.verbose >= VERBOSE_MINIMAL:
        #     print("\nCTOæ€»ç»“æµ‹è¯•ç”¨ä¾‹")
        # cto_session_id = self.cto_agent.start_new_session()
        # final_test_cases = self.cto_agent.summarize_test_cases(
        #     problem_description=problem_description,
        #     test_results=all_test_results,
        #     sample_io=sample_io,
        #     attention_analysis=test_agent_attention,
        #     session_id=cto_session_id
        # )
        
        # ä½¿ç”¨AttentionAgentå¯¹é˜¶æ®µä¸€ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œå®¡è®¡/æ”¹é”™
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nğŸ”§ ä½¿ç”¨AttentionAgentå®¡è®¡/æ”¹é”™æµ‹è¯•ç”¨ä¾‹ï¼ˆé˜¶æ®µä¸€ï¼‰...")
        # æå–åŸå§‹æµ‹è¯•ç”¨ä¾‹æ–­è¨€åˆ—è¡¨
        original_cases = []
        if isinstance(test_agent_structured, dict):
            items = test_agent_structured.get("test_cases", [])
            for it in items:
                if isinstance(it, dict) and it.get("assertion"):
                    original_cases.append(it["assertion"]) 
                elif isinstance(it, str) and it.strip().startswith("assert"):
                    original_cases.append(it.strip())
        
        # ä»…ä¿ç•™å‰8ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆè‹¥ä¸è¶³8ä¸ªåˆ™ä¸å¤„ç†ï¼‰
        if len(original_cases) > 8:
            original_cases = original_cases[:8]

        corrected_testcases = self._correct_failed_testcases(
            problem_description=problem_description,
            failed_testcases=['most is wrong,please fix them'],  # é˜¶æ®µä¸€æ— å¤±è´¥ç”¨ä¾‹ï¼Œä¹Ÿæ‰§è¡Œå®¡è®¡
            all_testcases=original_cases,
            attenton_analysis=attention_dict,
            sample_io=sample_io or [],
            stage=1
        )
        
        # æ„å»ºfinal_test_casesï¼Œä¿æŒä¸ä¸‹æ¸¸å…¼å®¹
        final_test_cases = {
            "thought": test_agent_thought,
            "structured_data": {
                "test_cases": [{"assertion": s, "description": ""} for s in corrected_testcases]
            }
        }
        
        
        elapsed_time = time.time() - start_time
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\næµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            
            # è·å–æµ‹è¯•ç”¨ä¾‹æ•°é‡
            test_case_count = "æœªçŸ¥"
            if final_test_cases.get("structured_data") and "test_cases" in final_test_cases["structured_data"]:
                test_case_count = len(final_test_cases["structured_data"]["test_cases"])
            print(f"ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {test_case_count}")
        
        return final_test_cases
    
    def _generate_test_scenarios(self, problem_description: str, problem_sample_io: List[str] = None, attention_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        é˜¶æ®µ 1.1: ç”Ÿæˆæµ‹è¯•åœºæ™¯
        
        Args:
            problem_description: é—®é¢˜æè¿°
            problem_sample_io: é—®é¢˜çš„æ ·ä¾‹è¾“å…¥è¾“å‡º
            attention_analysis: é˜¶æ®µé›¶çš„é‡ç‚¹åˆ†æç»“æœ
            
        Returns:
            ç”Ÿæˆçš„æµ‹è¯•åœºæ™¯
        """
        import time
        start_time = time.time()
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'='*50}")
            print("é˜¶æ®µ 1.1: ç”Ÿæˆæµ‹è¯•åœºæ™¯")
            print(f"{'='*50}")
        
        # æå– attention_analysis çš„å†…å®¹
        attention_analysis_str = ""
        if attention_analysis:
            if isinstance(attention_analysis, dict):
                # ä¼˜å…ˆä½¿ç”¨ raw_responseï¼Œå…¶æ¬¡æ˜¯ fatal_points
                attention_analysis_str = attention_analysis.get('raw_response', 
                                                             attention_analysis.get('fatal_points', ''))
            else:
                attention_analysis_str = str(attention_analysis)
        
        if not attention_analysis_str:
            attention_analysis_str = "No previous analysis available"
        
        # ä½¿ç”¨ TestAgent çš„åœºæ™¯ç”ŸæˆåŠŸèƒ½
        try:
            from prompts.testing.test_agent import get_scenario_generation_messages
            
            messages = get_scenario_generation_messages(
                problem_description=problem_description,
                attention_analysis=attention_analysis_str,
                problem_sample_io=problem_sample_io or []
            )
            
            # åˆ›å»ºæ–°çš„sessionç”¨äºæµ‹è¯•åœºæ™¯ç”Ÿæˆ
            scenario_session_id = self.test_agent.start_new_session()
            response = self.test_agent._call_model(messages, session_id=scenario_session_id)
            
            # è§£æå“åº”ä¸­çš„JSON
            import re
            import json
            
            # å°è¯•æå–JSONå—
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL | re.IGNORECASE)
            if not json_match:
                json_match = re.search(r'```\s*(.*?)\s*```', response, re.DOTALL | re.IGNORECASE)
            
            test_scenarios = []
            if json_match:
                try:
                    json_content = json_match.group(1).strip()
                    parsed_json = json.loads(json_content)
                    test_scenarios = parsed_json.get('test_scenarios', [])
                except json.JSONDecodeError as e:
                    if self.verbose >= VERBOSE_MINIMAL:
                        print(f"JSONè§£æå¤±è´¥: {e}")
                    test_scenarios = []
            
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\nğŸ¯ ç”Ÿæˆçš„æµ‹è¯•åœºæ™¯æ•°é‡: {len(test_scenarios)}")
                if test_scenarios and self.verbose >= VERBOSE_FULL:
                    for i, scenario in enumerate(test_scenarios[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"  åœºæ™¯ {i+1}:")
                        print(f"    è¾“å…¥: {scenario.get('input', 'N/A')}")
                        print(f"    æè¿°: {scenario.get('description', 'N/A')}")
                        if i < len(test_scenarios) - 1:
                            print()
            
            elapsed_time = time.time() - start_time
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"\næµ‹è¯•åœºæ™¯ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
                print(f"{'='*50}\n")
            
            return {
                "test_scenarios": test_scenarios,
                "raw_response": response,
                "generation_time": elapsed_time,
                "session_id": scenario_session_id
            }
            
        except Exception as e:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"âŒ æµ‹è¯•åœºæ™¯ç”Ÿæˆå¤±è´¥: {e}")
            
            elapsed_time = time.time() - start_time
            return {
                "test_scenarios": [],
                "raw_response": "",
                "generation_time": elapsed_time,
                "error": str(e)
            }
        
    def _plan_solution(self, problem_description, test_cases, thought_content, problem_sample_io, attention_analysis: Dict[str, Any] = None, stage_error_analysis: Dict[str, Any] = None):
        """
        è§„åˆ’è§£å†³æ–¹æ¡ˆ
        
        Args:
            problem_description: é—®é¢˜æè¿°
            test_cases: æµ‹è¯•ç”¨ä¾‹
            attention_analysis: é˜¶æ®µé›¶çš„é‡ç‚¹åˆ†æç»“æœ
            
        Returns:
            æœ€ç»ˆçš„æŠ€æœ¯æ–¹æ¡ˆ
        """
        if self.verbose >= VERBOSE_MINIMAL:
            print("\n=== é˜¶æ®µ2: è§„åˆ’è§£å†³æ–¹æ¡ˆ ===")
        
        
        # ç¬¬ä¸€æ­¥: è§£å†³æ–¹æ¡ˆè§„åˆ’Agentç‹¬ç«‹ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nç¬¬ä¸€æ­¥: è§£å†³æ–¹æ¡ˆè§„åˆ’Agentç”Ÿæˆåˆæ­¥è§£å†³æ–¹æ¡ˆ")
        
        if test_cases is None:
            test_cases = [('no test cases','there is no test cases,you should think the plan by yourself')]

      
        test_cases_for_plan = test_cases
        thought_content=""
        print("test_cases_for_plan:\n\n", test_cases_for_plan,"\n\n")
        
        # é‡æ–°æå–fatal_pointsç”¨äºsolution planningé˜¶æ®µ
        fatal_points_str = 'N/A'
        if attention_analysis:
            if isinstance(attention_analysis, dict):
                fatal_points_str = attention_analysis.get('raw_response', 'N/A')
            else:
                fatal_points_str = str(attention_analysis)
        attention_dict = {"fatal_points": fatal_points_str} if fatal_points_str != 'N/A' else None
        
        solution_planning_session_id = self.solution_planning_agent.start_new_session()
        # ä½¿ç”¨è§£å†³æ–¹æ¡ˆè§„åˆ’Agentç”Ÿæˆåˆæ­¥è§£å†³æ–¹æ¡ˆ
        initial_solutions = self.solution_planning_agent.generate_solutions(
            problem_description=problem_description,
            test_cases=test_cases_for_plan,
            thought_content=thought_content,
            problem_sample_io=problem_sample_io,
            attention_analysis=attention_dict,
            session_id=solution_planning_session_id
        )
        
        # å…ˆè·å–ç»“æ„åŒ–æ•°æ®ç”¨äºæ‰“å°
        structured_data = initial_solutions.get("raw_response", {})

        
 
        return structured_data
        
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nè¿›å…¥CTOè¯„å®¡å®Œå–„é˜¶æ®µ")

        # CTOè¯„å®¡å¹¶å®Œå–„åˆæ­¥æ–¹æ¡ˆ
        final_technical_plan = self.cto_agent.review_and_refine_solution(
            problem_description=problem_description,
            initial_solutions=initial_solutions,
            test_cases=problem_sample_io,
            thought_content=thought_content,
            problem_sample_io=problem_sample_io,
            attention_analysis=attention_analysis
        )

        if self.verbose >= VERBOSE_FULL:
            print("CTOè¯„å®¡å®Œå–„ç»“æœ:")
            if final_technical_plan.get("thought"):
                print("æ€è€ƒè¿‡ç¨‹:", final_technical_plan["thought"])
            if final_technical_plan.get("structured_data"):
                print("å®Œå–„åçš„æŠ€æœ¯æ–¹æ¡ˆ:", final_technical_plan["structured_data"])

        return final_technical_plan


    def _generate_code(self, problem_description, test_cases, parsed_assertions, thought_content, technical_plan, problem_sample_io, attention_analysis: Dict[str, Any] = None, stage_error_analysis: Dict[str, Any] = None, error_code: str = None, error_info: str = None, item: Dict[str, Any] = None):
        """
        é˜¶æ®µä¸‰: ç”Ÿæˆä»£ç 
        
        Args:
            problem_description: é—®é¢˜æè¿°
            test_cases: æµ‹è¯•ç”¨ä¾‹
            technical_plan: æŠ€æœ¯æ–¹æ¡ˆ
            problem_sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            attention_analysis: é˜¶æ®µé›¶çš„é‡ç‚¹åˆ†æç»“æœ
            
        Returns:
            ç”Ÿæˆçš„ä»£ç 
        """
        if self.verbose >= VERBOSE_MINIMAL:
            print("\n=== é˜¶æ®µ3: ç”Ÿæˆä»£ç  ===")

         # é‡æ–°æå–fatal_pointsç”¨äºsolution planningé˜¶æ®µ
        fatal_points_str = 'N/A'
        if attention_analysis:
            if isinstance(attention_analysis, dict):
                fatal_points_str = attention_analysis.get('raw_response', 'N/A')
            else:
                fatal_points_str = str(attention_analysis)
        attention_dict = {"fatal_points": fatal_points_str} if fatal_points_str != 'N/A' else None

        # ä½¿ç”¨ä»£ç ç”Ÿæˆæ™ºèƒ½ä½“ç”Ÿæˆä»£ç 
        code_session_id = self.code_agent.start_new_session()
        code_result = self.code_agent.generate_code(
            problem_description=problem_description,
            test_cases=test_cases,
            technical_plan=technical_plan,
            language=self.language,
            problem_sample_io=problem_sample_io,
            attention_analysis=attention_dict,
            error_code=error_code,
            error_info=error_info,
            session_id=code_session_id
        )
        print("code_result:\n\n", code_result,"\n\n")
        
        # è·å–ç”Ÿæˆçš„ä»£ç å’Œä¼šè¯ID
        generated_code = code_result.get("code", "")
        
        # ä½¿ç”¨è¯­æ³•æ£€æŸ¥å™¨æ£€æŸ¥ä»£ç ï¼ˆä»…é’ˆå¯¹ Python è¯­è¨€ï¼‰
        grammar_summary = None
        if isinstance(self.language, str) and self.language.lower().startswith("python"):
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nğŸ§¹ è¿è¡Œè¯­æ³•æ£€æŸ¥å™¨ (pyflakes)...")

            grammar_context = {
                "problem_description": problem_description,
                "test_cases": problem_sample_io if isinstance(problem_sample_io, list) else [],
            }

            try:
                grammar_result = self.grammar_checker.ensure_clean(
                    generated_code,
                    context=grammar_context,
                )
            except RuntimeError as exc:
                grammar_summary = {
                    "success": False,
                    "fixed": False,
                    "attempts": 0,
                    "report": str(exc),
                    "issues": [],
                    "history": [],
                    "error": str(exc),
                }
                code_result["grammar_check"] = grammar_summary
                if self.verbose >= VERBOSE_MINIMAL:
                    print(f"è¯­æ³•æ£€æŸ¥å™¨ä¸å¯ç”¨: {exc}")
            else:
                def _issue_to_dict(issue):
                    return {
                        "line": issue.line,
                        "column": issue.column,
                        "message": issue.message,
                        "raw": issue.raw,
                    }

                grammar_summary = {
                    "success": grammar_result.success,
                    "fixed": grammar_result.fixed,
                    "attempts": grammar_result.attempts,
                    "report": grammar_result.report,
                    "issues": [_issue_to_dict(it) for it in grammar_result.issues],
                    "history": grammar_result.history,
                }

                generated_code = grammar_result.code
                code_result["code"] = generated_code
                code_result["grammar_check"] = grammar_summary

                if self.verbose >= VERBOSE_MINIMAL:
                    status = "é€šè¿‡" if grammar_result.success else "å¤±è´¥"
                    print(f"è¯­æ³•æ£€æŸ¥ç»“æœ: {status}")
                    if not grammar_result.success and grammar_result.issues:
                        for issue in grammar_result.issues[:5]:
                            loc = f"è¡Œ {issue.line}" if issue.line else "æœªçŸ¥ä½ç½®"
                            print(f"  - {loc}: {issue.message}")

        code_session_id = code_result.get("session_id")       

        print(f"final generated_code:\n\n{generated_code}\n\n")

        # å¤„ç†sample_ioï¼Œç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªåˆ—è¡¨
        sample_io_list = None
        if problem_sample_io and isinstance(problem_sample_io, list):
            sample_io_list = problem_sample_io
        elif problem_sample_io and isinstance(problem_sample_io, str):
            sample_io_list = problem_sample_io.strip().split("\n")
        
        # æ‰“å°sample_ioä¿¡æ¯
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nSample I/O tests:")
            if sample_io_list:
                for i, test in enumerate(sample_io_list):
                    print(f"  Test {i+1}: {test}")
            else:
                print("  No sample I/O tests available")
        
        # å¦‚æœæ²¡æœ‰sample_ioï¼Œç›´æ¥è¿”å›ä»£ç 
        if not sample_io_list:
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nNo sample I/O tests available. Skipping testing phase.")
            code_result["success"] = True
            code_result["attempts"] = 0
            return code_result
        
        # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©æµ‹è¯•æ–¹å¼
        if self.verbose >= VERBOSE_MINIMAL:
            print("\n=== ç¬¬ä¸€å±‚æµ‹è¯•: Sample I/O ===")
        
        if self.is_competitive and item:
            # APPS: ä½¿ç”¨ ExecEval æµ‹è¯•ï¼ˆinput/output æ ¼å¼ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print("ä½¿ç”¨ ExecEval æµ‹è¯• APPS ä»£ç ...")
            
            sample_io_passed, test_log = self.dataset.evaluate_sample_io(
                item=item,
                code=generated_code,
                language=self.language
            )
            
            # æ„å»ºä¸ DebugAgent å…¼å®¹çš„ç»“æœæ ¼å¼
            sample_io_result = {
                "success": sample_io_passed,
                "output": test_log,
                "error": "" if sample_io_passed else test_log,
                "error_type": None if sample_io_passed else "ExecEval",
                "failed_tests": [] if sample_io_passed else [{"test": "APPS test", "error": test_log}]
            }
        else:
            # HumanEval/MBPP: ä½¿ç”¨ DebugAgent æœ¬åœ°æµ‹è¯•ï¼ˆassert è¯­å¥ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print("ä½¿ç”¨æœ¬åœ°æ‰§è¡Œæµ‹è¯•ä»£ç ...")
            
            sample_io_result = self.debug_agent.test_with_sample_io(
                code=generated_code,
                sample_io=sample_io_list,
                timeout=10
            )
            sample_io_passed = sample_io_result["success"]
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"Sample I/O æµ‹è¯•ç»“æœ: {'é€šè¿‡' if sample_io_passed else 'å¤±è´¥'}")
        
        # ç¬¬äºŒå±‚æµ‹è¯•ï¼šæµ‹è¯•parsed assertions (å¦‚æœæœ‰çš„è¯)
        testcase_passed = True
        code_result["code"]=generated_code
        code_result["success"] = sample_io_passed
        return code_result   
        discussion_validation_threshold=1.0
        # æ ¹æ®æµ‹è¯•ç»“æœå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        if sample_io_passed and testcase_passed:
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nğŸ‰ ä»£ç é€šè¿‡æ‰€æœ‰æµ‹è¯•ï¼")
            code_result["code"] = generated_code
            code_result["success"] = True
            code_result["attempts"] = 1
            return code_result            
        elif not sample_io_passed :
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nâŒ Sample I/O æµ‹è¯•å¤±è´¥ï¼Œè¿›å…¥è®¨è®º...")
            test_cases_for_discussion = problem_sample_io
            failed_tests = sample_io_result.get('failed_tests', [])
            discussion_topic = "Fix code to pass failing Sample I/O"
            discussion_validation_threshold = 1.0  # 100%éªŒè¯
       
        
        # å¯åŠ¨å¤šæ™ºèƒ½ä½“è°ƒè¯•æœºåˆ¶
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"Failed tests: {len(failed_tests)}")
            print("\nğŸ”§ å¯åŠ¨å¤šæ™ºèƒ½ä½“è°ƒè¯•ç³»ç»Ÿ...")

        from utils.dialogue import MultiAgentDebugger
        
        # åˆ›å»ºå¤šæ™ºèƒ½ä½“è°ƒè¯•å™¨ï¼ˆä½¿ç”¨ä¸workflowç›¸åŒçš„æ¨¡å‹ï¼‰
        debugger = MultiAgentDebugger(model=self.model, verbose=self.verbose)
        if self.is_competitive:
            error_logs = failed_tests[0].get('error')
        else:
            # æ„å»ºé”™è¯¯æ—¥å¿—
            error_logs = "\n".join([f"Test failed: {ft.get('error', 'Unknown error')}" for ft in failed_tests])
        
        # ä½¿ç”¨å¤šæ™ºèƒ½ä½“è°ƒè¯•å™¨ä¿®å¤ä»£ç 
        debug_result = debugger.debug_problem(
            problem_description=problem_description,
            current_code=generated_code,
            test_cases=test_cases_for_discussion,
            error_logs=error_logs,
            attention_analysis=attention_dict,
            init_code=error_code,
            is_competive=self.is_competitive,
            item=item,
            dataset=self.dataset
        )
        
        # å¤„ç†è°ƒè¯•ç»“æœ
        if debug_result["success"]:
            if self.verbose >= VERBOSE_MINIMAL:
                print("âœ… å¤šæ™ºèƒ½ä½“è°ƒè¯•å™¨æˆåŠŸä¿®å¤ä»£ç !")
            extracted_code = debug_result["final_code"]
        else:
            if self.verbose >= VERBOSE_MINIMAL:
                print(f"âŒ å¤šæ™ºèƒ½ä½“è°ƒè¯•å™¨ä¿®å¤å¤±è´¥: {debug_result.get('error', 'Unknown error')}")
            extracted_code = generated_code  # ä½¿ç”¨åŸå§‹ä»£ç 
        code_result["code"] = extracted_code
        code_result["attempts"] = 1
        code_result["failed_sample_io"] = sample_io_result if not sample_io_passed else "N/A"
        if debug_result.get("success"):
            code_result["debug_enhanced"] = True
            code_result["debug_history"] = debug_result.get("execution_history", [])
        return code_result
    

    def _generate_init_code(self, problem_description, problem_sample_io, item: Dict[str, Any] = None):
        """
        é˜¶æ®µä¸‰: ç”Ÿæˆä»£ç 
        
        Args:
            problem_description: é—®é¢˜æè¿°
            test_cases: æµ‹è¯•ç”¨ä¾‹
            problem_sample_io: æ ·ä¾‹è¾“å…¥è¾“å‡º
            item: æ•°æ®é¡¹ï¼ˆç”¨äº APPS ç­‰ç«èµ›å‹æ•°æ®é›†çš„ ExecEval è¯„ä¼°ï¼‰
            
        Returns:
            ç”Ÿæˆçš„ä»£ç 
        """
        if self.verbose >= VERBOSE_MINIMAL:
            print("\n=== é˜¶æ®µ3: ç”Ÿæˆä»£ç  ===")


        # ä½¿ç”¨ä»£ç ç”Ÿæˆæ™ºèƒ½ä½“ç”Ÿæˆä»£ç 
        code_session_id = self.code_agent.start_new_session()
        code_result = self.code_agent.generate_init_code(
            problem_description=problem_description,
            language=self.language,
            problem_sample_io=problem_sample_io,
            session_id=code_session_id
        )
        print("code_result:\n\n", code_result,"\n\n")
        
        # è·å–ç”Ÿæˆçš„ä»£ç å’Œä¼šè¯ID
        generated_code = code_result.get("code", "")
        
        # ä½¿ç”¨è¯­æ³•æ£€æŸ¥å™¨æ£€æŸ¥ä»£ç ï¼ˆä»…é’ˆå¯¹ Python è¯­è¨€ï¼‰
        grammar_summary = None
        if isinstance(self.language, str) and self.language.lower().startswith("python"):
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nğŸ§¹ è¿è¡Œè¯­æ³•æ£€æŸ¥å™¨ (pyflakes)...")

            grammar_context = {
                "problem_description": problem_description,
                "test_cases": problem_sample_io if isinstance(problem_sample_io, list) else [],
            }

            try:
                grammar_result = self.grammar_checker.ensure_clean(
                    generated_code,
                    context=grammar_context,
                )
            except RuntimeError as exc:
                grammar_summary = {
                    "success": False,
                    "fixed": False,
                    "attempts": 0,
                    "report": str(exc),
                    "issues": [],
                    "history": [],
                    "error": str(exc),
                }
                code_result["grammar_check"] = grammar_summary
                if self.verbose >= VERBOSE_MINIMAL:
                    print(f"è¯­æ³•æ£€æŸ¥å™¨ä¸å¯ç”¨: {exc}")
            else:
                def _issue_to_dict(issue):
                    return {
                        "line": issue.line,
                        "column": issue.column,
                        "message": issue.message,
                        "raw": issue.raw,
                    }

                grammar_summary = {
                    "success": grammar_result.success,
                    "fixed": grammar_result.fixed,
                    "attempts": grammar_result.attempts,
                    "report": grammar_result.report,
                    "issues": [_issue_to_dict(it) for it in grammar_result.issues],
                    "history": grammar_result.history,
                }

                generated_code = grammar_result.code
                code_result["code"] = generated_code
                code_result["grammar_check"] = grammar_summary

                if self.verbose >= VERBOSE_MINIMAL:
                    status = "é€šè¿‡" if grammar_result.success else "å¤±è´¥"
                    print(f"è¯­æ³•æ£€æŸ¥ç»“æœ: {status}")
                    if not grammar_result.success and grammar_result.issues:
                        for issue in grammar_result.issues[:5]:
                            loc = f"è¡Œ {issue.line}" if issue.line else "æœªçŸ¥ä½ç½®"
                            print(f"  - {loc}: {issue.message}")

        code_session_id = code_result.get("session_id")
       
        print(f"final generated_code:\n\n{generated_code}\n\n")

        # å¤„ç†sample_ioï¼Œç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªåˆ—è¡¨
        sample_io_list = None
        if problem_sample_io and isinstance(problem_sample_io, list):
            sample_io_list = problem_sample_io
        elif problem_sample_io and isinstance(problem_sample_io, str):
            sample_io_list = problem_sample_io.strip().split("\n")
        
        # æ‰“å°sample_ioä¿¡æ¯
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nSample I/O tests:")
            if sample_io_list:
                for i, test in enumerate(sample_io_list):
                    print(f"  Test {i+1}: {test}")
            else:
                print("  No sample I/O tests available")
        
        # å¦‚æœæ²¡æœ‰sample_ioï¼Œç›´æ¥è¿”å›ä»£ç 
        if not sample_io_list:
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nNo sample I/O tests available. Skipping testing phase.")
            code_result["success"] = True
            code_result["attempts"] = 0
            return code_result
        
        # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©æµ‹è¯•æ–¹å¼
        if self.verbose >= VERBOSE_MINIMAL:
            print("\n=== ç¬¬ä¸€å±‚æµ‹è¯•: Sample I/O ===")
        
        if self.is_competitive and item:
            # APPS: ä½¿ç”¨ ExecEval æµ‹è¯•ï¼ˆinput/output æ ¼å¼ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print("ä½¿ç”¨ ExecEval æµ‹è¯• APPS ä»£ç ...")
            
            sample_io_passed, test_log = self.dataset.evaluate_sample_io(
                item=item,
                code=generated_code,
                language=self.language
            )
            
            # æ„å»ºä¸ DebugAgent å…¼å®¹çš„ç»“æœæ ¼å¼
            sample_io_result = {
                "success": sample_io_passed,
                "output": test_log,
                "error": "" if sample_io_passed else test_log,
                "error_type": None if sample_io_passed else "ExecEval",
                "failed_tests": [] if sample_io_passed else [{"test": "APPS test", "error": test_log}]
            }
        else:
            # HumanEval/MBPP: ä½¿ç”¨ DebugAgent æœ¬åœ°æµ‹è¯•ï¼ˆassert è¯­å¥ï¼‰
            if self.verbose >= VERBOSE_MINIMAL:
                print("ä½¿ç”¨æœ¬åœ°æ‰§è¡Œæµ‹è¯•ä»£ç ...")
            
            sample_io_result = self.debug_agent.test_with_sample_io(
                code=generated_code,
                sample_io=sample_io_list,
                timeout=10
            )
            sample_io_passed = sample_io_result["success"]
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"Sample I/O æµ‹è¯•ç»“æœ: {'é€šè¿‡' if sample_io_passed else 'å¤±è´¥'}")
        
        # ç¬¬äºŒå±‚æµ‹è¯•ï¼šæµ‹è¯•parsed assertions (å¦‚æœæœ‰çš„è¯)
        testcase_passed = True
      
       
        discussion_validation_threshold=1.0
        # æ ¹æ®æµ‹è¯•ç»“æœå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        if sample_io_passed:
            if self.verbose >= VERBOSE_MINIMAL:
                print("\nğŸ‰ ä»£ç é€šè¿‡æ‰€æœ‰æµ‹è¯•ï¼")
            code_result["code"] = generated_code
            code_result["success"] = True
            code_result["attempts"] = 1
            return code_result            
        elif not sample_io_passed :
            code_result["code"] = generated_code
            code_result["success"] = False
            code_result["error"]=sample_io_result.get('failed_tests', [])
            return code_result
       
        
        
        return code_result

    def _save_generated_code(self, test_cases, code):
        """
        ä¿å­˜ç”Ÿæˆçš„ä»£ç åˆ°æ–‡ä»¶ï¼Œä»¥ä¾¿åç»­è¯„ä¼°
        
        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹
            code: ç”Ÿæˆçš„ä»£ç 
        """
        # è·å–ä»»åŠ¡ID
        task_id = ""
        if isinstance(test_cases, dict) and "task_id" in test_cases:
            task_id = test_cases["task_id"]
        
        if not task_id:
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        model_dir = f"results/solutions/{self.model.model_name}"
        os.makedirs(model_dir, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è§£å†³æ–¹æ¡ˆæ–‡ä»¶
        solution_file = f"{model_dir}/solutions.jsonl"
        
        # å‡†å¤‡è§£å†³æ–¹æ¡ˆæ•°æ®
        solution_data = {
            "task_id": task_id,
            "model": self.model.model_name,
            "language": self.language,
            "timestamp": time.time(),
            "code": code
        }
        
        # è¿½åŠ åˆ°æ–‡ä»¶
        with open(solution_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(solution_data) + "\n")
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\nä»£ç å·²ä¿å­˜åˆ°: {solution_file}")
            
        # åˆ›å»ºä»»åŠ¡ç‰¹å®šçš„ç›®å½•
        task_dir = f"{model_dir}/{task_id.split('/')[0]}"  # æå–ä¸»è¦éƒ¨åˆ†ï¼Œå¦‚HumanEval
        os.makedirs(task_dir, exist_ok=True)
            
        # åŒæ—¶ä¿å­˜åˆ°ä»»åŠ¡ç‰¹å®šçš„æ–‡ä»¶
        task_file = f"{task_dir}/{task_id.split('/')[-1]}.json"  # ä½¿ç”¨æœ€åéƒ¨åˆ†ä½œä¸ºæ–‡ä»¶åï¼Œå¦‚0.json
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»»åŠ¡ç‰¹å®šæ–‡ä»¶
        if os.path.exists(task_file):
            # è¯»å–ç°æœ‰è§£å†³æ–¹æ¡ˆ
            with open(task_file, "r", encoding="utf-8") as f:
                task_data = json.load(f)
                
            # æ·»åŠ æ–°è§£å†³æ–¹æ¡ˆ
            if "solutions" in task_data:
                task_data["solutions"].append(code)
            else:
                task_data["solutions"] = [code]
        else:
            # åˆ›å»ºæ–°çš„ä»»åŠ¡æ•°æ®
            task_data = {
                "task_id": task_id,
                "model": self.model.model_name,
                "language": self.language,
                "solutions": [code]
            }
        
        # ä¿å­˜ä»»åŠ¡ç‰¹å®šæ–‡ä»¶
        with open(task_file, "w", encoding="utf-8") as f:
            json.dump(task_data, f, indent=2)
            
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"ä»»åŠ¡ç‰¹å®šä»£ç å·²ä¿å­˜åˆ°: {task_file}")
    
    def _execute_and_verify(self, item: Dict[str, Any], code: str) -> Tuple[bool, str]:
        """
        é˜¶æ®µå››: Dockerç¯å¢ƒçš„æ‰§è¡ŒéªŒè¯
        
        Args:
            item: æ•°æ®é¡¹
            code: ç”Ÿæˆçš„ä»£ç 
            
        Returns:
            (æ˜¯å¦é€šè¿‡, æµ‹è¯•æ—¥å¿—)
        """
        start_time = time.time()
        
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\n{'-'*50}\né˜¶æ®µå››: Dockerç¯å¢ƒçš„æ‰§è¡ŒéªŒè¯\n{'-'*50}")
        
        # ç¬¬ä¸€æ­¥: å®¹å™¨åŒ–æ‰§è¡Œæµ‹è¯•
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nç¬¬ä¸€æ­¥: å®¹å™¨åŒ–æ‰§è¡Œæµ‹è¯•")
        
        if self.docker_execution:
            passed, test_log = self.docker_executor.execute(
                item,
                code,
                self.language,
                self.dataset
            )
        else:
            # å¦‚æœä¸ä½¿ç”¨Dockerï¼Œåˆ™ä½¿ç”¨æ•°æ®é›†çš„å†…ç½®è¯„ä¼°æ–¹æ³•
            passed, test_log = self.dataset.evaluate_sample_io(
                item,
                code,
                self.language
            )
        
        # ç¬¬äºŒæ­¥: ç»“æœåˆ†æå’Œè¿­ä»£ä¼˜åŒ–
        if self.verbose >= VERBOSE_MINIMAL:
            print("\nç¬¬äºŒæ­¥: ç»“æœåˆ†æå’Œè¿­ä»£ä¼˜åŒ–")
            print(f"æ‰§è¡Œç»“æœ: {'é€šè¿‡' if passed else 'å¤±è´¥'}")
            if not passed and self.verbose >= VERBOSE_FULL:
                print(f"æµ‹è¯•æ—¥å¿—:\n{test_log}")
        
        elapsed_time = time.time() - start_time
        if self.verbose >= VERBOSE_MINIMAL:
            print(f"\næ‰§è¡ŒéªŒè¯å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
        return passed, test_log